{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler, LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEEDS TO READ FROM SQL\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/cdj3e/vu_bootcamp/Project_4/Resources/heart_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"age\": \"Age\", \"sex\": \"Sex\", \"cp\": \"Chest Pain Type\", \"trestbps\": \"Resting BP\", \"chol\": \"Cholesterol\", \"fbs\": \"Fasting Blood Sugar\", \"restecg\": \"Resting ECG\", \"thalach\": \"Max Heart Rate\", \"exang\": \"Exercise Induced Angina\", \"oldpeak\": \"OldPeak\", \"slope\": \"ST Slope\", \"num\": \"Heart Disease\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string_col = df.select_dtypes(include=\"int64\").columns\n",
    "#df[string_col]=df[string_col].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation\n",
    "\n",
    "px.imshow(df.corr(),title=\"Heart Disease Prediction Correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram correlation\n",
    "\n",
    "fig=px.histogram(df, \n",
    "                 x=\"Heart Disease\",\n",
    "                 color=\"Sex\",\n",
    "                 hover_data=df.columns,\n",
    "                 title=\"Heart Disease by Sex\",\n",
    "                 barmode=\"group\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram distribution\n",
    "\n",
    "fig=px.histogram(df,\n",
    "                 x=\"Age\",\n",
    "                 hover_data=df.columns,\n",
    "                 title=\"Distribution of Age\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot\n",
    "\n",
    "sns.pairplot(df,hue=\"Heart Disease\")\n",
    "plt.tight_layout()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution shape by kernel density estimate\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    plt.subplot(4,3,i)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.tight_layout()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot distribution\n",
    "\n",
    "fig = px.box(df,y=\"Resting BP\",x=\"Heart Disease\",title=f\"Resting BP Distribution by FBS\",color=\"Sex\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop to determine best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Heart Disease']\n",
    "X = df.drop(columns='Heart Disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\"Logistic Regression\": LogisticRegression(),\n",
    "        \"SVM\": SVC(),\n",
    "        \"Naive Bayers\": GaussianNB(),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "        \"Random Forest Classifier\": RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit\n",
    "\n",
    "    y_prediction=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_prediction=model.predict(X_test)\n",
    "\n",
    "    accuracy=accuracy_score(y_test,y_prediction)\n",
    "\n",
    "    print(str(list(models.keys())[i])+\" Score = \", accuracy)\n",
    "\n",
    "    plt.suptitle('Accuracy', color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varieties of Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.RobustScaler()\n",
    "robust_scaling_df = scaler.fit_transform(df)\n",
    "robust_scaling_df = pd.DataFrame(robust_scaling_df, columns =['Age', 'Sex', 'Chest Pain Type', 'Resting BP', 'Cholesterol', 'Fasting Blood Sugar', 'Resting ECG', 'Max Heart Rate', 'Exercise Induced Angina', 'OldPeak', 'ST Slope', 'Heart Disease'])\n",
    " \n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard_scaling_df = scaler.fit_transform(df)\n",
    "standard_scaling_df = pd.DataFrame(standard_scaling_df, columns =['Age', 'Sex', 'Chest Pain Type', 'Resting BP', 'Cholesterol', 'Fasting Blood Sugar', 'Resting ECG', 'Max Heart Rate', 'Exercise Induced Angina', 'OldPeak', 'ST Slope', 'Heart Disease'])\n",
    " \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "minmax_scaling_df = scaler.fit_transform(df)\n",
    "minmax_scaling_df = pd.DataFrame(minmax_scaling_df, columns =['Age', 'Sex', 'Chest Pain Type', 'Resting BP', 'Cholesterol', 'Fasting Blood Sugar', 'Resting ECG', 'Max Heart Rate', 'Exercise Induced Angina', 'OldPeak', 'ST Slope', 'Heart Disease'])\n",
    "\n",
    "fig, (unscaled, robust, standard, minmax) = plt.subplots(ncols = 4, figsize =(20, 5))\n",
    "\n",
    "unscaled.set_title('Unscaled')\n",
    "sns.kdeplot(df['Chest Pain Type'], ax = unscaled, color ='red')\n",
    "sns.kdeplot(df['Heart Disease'], ax = unscaled, color ='black')\n",
    "\n",
    "robust.set_title('Robust Scaling')\n",
    "sns.kdeplot(robust_scaling_df['Chest Pain Type'], ax = robust, color ='red')\n",
    "sns.kdeplot(robust_scaling_df['Heart Disease'], ax = robust, color ='black')\n",
    "\n",
    "standard.set_title('Standard Scaling')\n",
    "sns.kdeplot(standard_scaling_df['Chest Pain Type'], ax = standard, color ='red')\n",
    "sns.kdeplot(standard_scaling_df['Heart Disease'], ax = standard, color ='black')\n",
    "\n",
    "minmax.set_title('Min/Max Scaling')\n",
    "sns.kdeplot(minmax_scaling_df['Chest Pain Type'], ax = minmax, color ='red')\n",
    "sns.kdeplot(minmax_scaling_df['Heart Disease'], ax = minmax, color ='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Tree Based Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold\n",
    "\n",
    "X = df.drop(columns='Heart Disease')\n",
    "y = df['Heart Disease']\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "\n",
    "stratified_k_fold = model_selection.StratifiedKFold(n_splits=10)\n",
    "accuracy = []\n",
    "\n",
    "for train_index, test_index in stratified_k_fold.split(X, y):\n",
    "    X_train=X_scaled[train_index]\n",
    "    y_train=y[train_index]\n",
    "    \n",
    "    X_test=X_scaled[test_index]\n",
    "    y_test=y[test_index]\n",
    "\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    accuracy.append(logistic_regression.score(X_test, y_test))\n",
    "\n",
    "print(\"Maximum Stratified K-Fold accuracy: \", max(accuracy)*100, \"%\")\n",
    "print(\"Minimum Stratified K-Fold accuracy: \", min(accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes\n",
    "\n",
    "NB_accuracy=[]\n",
    "    \n",
    "naive_bayers=GaussianNB()\n",
    "naive_bayers.fit(X_train,y_train)\n",
    "NB_accuracy.append(naive_bayers.score(X_test, y_test))\n",
    "\n",
    "print(\"Maximum Naive Bayers accuracy: \", max(NB_accuracy)*100, \"%\")\n",
    "print(\"Minimum Naive Bayers accuracy: \", min(NB_accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine linear kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "linear_SVC_accuracy=[]\n",
    "    \n",
    "svc_linear=SVC(kernel=\"linear\")\n",
    "svc_linear.fit(X_train,y_train)\n",
    "linear_SVC_accuracy.append(svc_linear.score(X_test, y_test))\n",
    "\n",
    "print(\"Maximum SVC (linear kernel) accuracy: \", max(linear_SVC_accuracy)*100, \"%\")\n",
    "print(\"Minimum SVC (linear kernel) accuracy: \", min(linear_SVC_accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine sigmoid kernel\n",
    "\n",
    "sigmoid_SVC_accuracy=[]\n",
    "    \n",
    "svc_sigmoid=SVC(kernel=\"sigmoid\")\n",
    "svc_sigmoid.fit(X_train,y_train)\n",
    "sigmoid_SVC_accuracy.append(svc_sigmoid.score(X_test, y_test))\n",
    "\n",
    "print(\"Maximum SVC (sigmoid kernel) accuracy: \", max(sigmoid_SVC_accuracy)*100, \"%\")\n",
    "print(\"Minimum SVC (sigmoid kernel) accuracy: \", min(sigmoid_SVC_accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine rbf kernel\n",
    "\n",
    "rbf_svc_accuracy=[]\n",
    "    \n",
    "svc_rbf=SVC(kernel=\"rbf\")\n",
    "svc_rbf.fit(X_train,y_train)\n",
    "rbf_svc_accuracy.append(svc_rbf.score(X_test, y_test))\n",
    "\n",
    "print(\"Maximum SVC (rbf kernel) accuracy: \", max(rbf_svc_accuracy)*100, \"%\")\n",
    "print(\"Minimum SVC (rbf kernel) accuracy: \", min(rbf_svc_accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine poly kernel\n",
    "\n",
    "poly_svc_accuracy=[]\n",
    "    \n",
    "svc_poly=SVC(kernel=\"poly\")\n",
    "svc_poly.fit(X_train,y_train)\n",
    "poly_svc_accuracy.append(svc_poly.score(X_test, y_test))\n",
    "\n",
    "print(\"Maximum SVC (poly kernel) accuracy: \", max(poly_svc_accuracy)*100, \"%\")\n",
    "print(\"Minimum SVC (poly kernel) accuracy: \", min(poly_svc_accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest neighbors \n",
    "\n",
    "k_nearest_neighbors_accuracy=[]\n",
    "    \n",
    "k_nearest_neighbors=KNeighborsClassifier(n_neighbors=32)\n",
    "k_nearest_neighbors.fit(X_train,y_train)\n",
    "k_nearest_neighbors_accuracy.append(k_nearest_neighbors.score(X_test, y_test))\n",
    "\n",
    "print(\"Maximum K-Nearest Neighbors accuracy: \", max(k_nearest_neighbors_accuracy)*100, \"%\")\n",
    "print(\"Minimum K-Nearest Neighbors accuracy: \", min(k_nearest_neighbors_accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree based algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(LabelEncoder().fit_transform)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_accuracy = []\n",
    "    \n",
    "decision_tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "decision_tree.fit(X_train,y_train)\n",
    "decision_tree_accuracy.append(decision_tree.score(X_test, y_test))\n",
    "\n",
    "print(\"Decision Tree accuracy: \", max(decision_tree_accuracy)*100, \"%\")\n",
    "#print(\"Minimum Decision Tree accuracy: \", min(decision_tree_accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier visualization\n",
    "\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "visual = tree.export_graphviz(decision_tree, out_file=None, \n",
    "                                feature_names=X,  \n",
    "                                class_names=y,\n",
    "                                filled=True)\n",
    "\n",
    "graph = graphviz.Source(visual, format=\"png\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "\n",
    "random_forest_accuracy = []\n",
    "    \n",
    "random_forest = RandomForestClassifier(n_estimators=200, criterion=\"entropy\")\n",
    "random_forest.fit(X_train,y_train)\n",
    "random_forest_accuracy.append(random_forest.score(X_test, y_test))\n",
    "\n",
    "print(\"Random Forest accuracy: \", max(random_forest_accuracy)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "importance = random_forest.feature_importances_\n",
    "idxs = np.argsort(importance)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.barh(range(len(idxs)),importance[idxs],align=\"center\")\n",
    "plt.yticks(range(len(idxs)),[X[i] for i in idxs])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
